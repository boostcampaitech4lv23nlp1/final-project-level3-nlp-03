{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Trailblazer-Yoo/boostcamp-docvqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import editdistance\n",
    "import transformers\n",
    "import random\n",
    "import gc\n",
    "import time\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import LayoutLMv2FeatureExtractor\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "from heapq import heappush\n",
    "from nltk.tag import pos_tag\n",
    "from typing import *\n",
    "import re\n",
    "\n",
    "def NLD(s1:str,s2:str) -> float:\n",
    "    return editdistance.eval(s1.lower(),s2.lower()) / ((len(s1)+len(s2))/2) # normalized_levenshtein_distance\n",
    "\n",
    "def check_answer(answer_list:List[str], words_list:List[str], boundary:int=0.2) -> float:\n",
    "    similarity_score = 0\n",
    "    for answer, word in zip(answer_list, words_list):\n",
    "        # print('answer word', answer, word)\n",
    "        ld_score = NLD(answer, word)\n",
    "\n",
    "        # 각 단어의 레벤슈타인 거리가 0.2보다 크면 너무 차이가 많아서 정답이 아님\n",
    "        if ld_score >= boundary:\n",
    "            return 100 # 레벤슈타인의 최대값은 1이므로 100은 나올 수 없음\n",
    "\n",
    "        else: similarity_score += ld_score\n",
    "        \n",
    "    return similarity_score / len(answer_list) # 가장 좋은 값은 0.0\n",
    "    \n",
    "def calculate_euclidean_mean(question_points:List[Tuple[int]], boxes:List[Tuple[int]]):\n",
    "    euclidean = 0\n",
    "    a_point = ((boxes[2] + boxes[0])/2, (boxes[3] + boxes[1])/2)\n",
    "    for q_point in question_points:\n",
    "        euclidean += ((a_point[0] - q_point[0])**2 + (a_point[1] - q_point[1])**2)**(1/2)\n",
    "        \n",
    "    return euclidean / len(question_points)\n",
    "\n",
    " \n",
    "def clean_text(raw_string:str) -> str:\n",
    "    #텍스트에 포함되어 있는 특수 문자 제거\n",
    "    text = re.sub('[-=+,#/\\?^$.@*\\※~ㆍ!…]','', raw_string)\n",
    " \n",
    "    return text\n",
    " \n",
    "def find_noun_ngram(questions:str, ngram:int) -> Set[Tuple[str]]:\n",
    "    if ngram == 1: # unigram일 경우\n",
    "        part_of_speech = {'NN', 'NNS','NNP', 'NNPS', 'POS','RP', 'CD', 'FW', 'VBG'}\n",
    "    else:\n",
    "        part_of_speech = {'NN', 'NNS','NNP', 'NNPS', 'IN', 'POS','RP', 'CD', 'FW', 'VBG', 'JJR', 'JJS', 'RBR', 'RBS'}\n",
    "        \n",
    "    result = set()\n",
    "    questions:List[str] = questions.split()\n",
    "    ngram_questions = [questions[i:i+ngram] for i in range(len(questions) - (ngram-1))]\n",
    "    for question in ngram_questions:\n",
    "        tmp_storage = []\n",
    "        for tag in pos_tag(question):\n",
    "            if tag[1] in part_of_speech:\n",
    "                tmp_storage.append(clean_text(tag[0]))\n",
    "                \n",
    "        if len(tmp_storage) == ngram:\n",
    "            result.add(tuple(tmp_storage))\n",
    "\n",
    "    yield from result\n",
    "\n",
    "def find_points(questions:str, words_list:List[str], boxes:List[List[int]], ngrams:int=3) -> List[Tuple[int]]:\n",
    "    question_words = sum([[ngram_question for ngram_question in find_noun_ngram(questions, ngram)] for ngram in range(1, ngrams+1)], [])\n",
    "    # boxes : (x1, y1, x2, y2)\n",
    "    result = []\n",
    "    for question in question_words:\n",
    "        question_list = list(question)\n",
    "        search_range = len(words_list) - (len(question_list)-1)\n",
    "        for idx, i in enumerate(range(search_range)):\n",
    "            nld = check_answer(question_list, words_list[i:i+len(question_list)], boundary=0.2)\n",
    "            if nld != 100:\n",
    "                if len(question) % 2 == 0:\n",
    "                    bb1 =boxes[idx+(len(question)//2)-1]\n",
    "                    bb2 = boxes[idx+(len(question)//2)]\n",
    "                    # \n",
    "                    bp1 = ((bb1[2] + bb1[0])/2, (bb1[3] + bb1[1])/2)\n",
    "                    bp2 = ((bb2[2] + bb2[0])/2, (bb2[3] + bb2[1])/2)\n",
    "                    result.append(((bb2[0] + bb1[0])/2, (bb2[1] + bb1[1])/2))\n",
    "                else:\n",
    "                    bb =boxes[idx+ (len(question)//2)]\n",
    "                    result.append(((bb[2] + bb[0])/2, (bb[3] + bb[1])/2))\n",
    "                    \n",
    "    return result\n",
    "\n",
    "def find_candidates(answer_list:List[str], words_list:List[str], questions, boxes):\n",
    "    nld_l = []\n",
    "    search_range = len(words_list) - (len(answer_list)-1)\n",
    "    for idx, i in enumerate(range(len(words_list))):\n",
    "        nld = check_answer(answer_list, words_list[i:i+len(answer_list)])\n",
    "        if nld != 100:\n",
    "            # 각 원소 : normalized_levenshtein_distance, answer, start_idx, end_idx\n",
    "            nld_l.append((nld, answer_list, idx, idx+len(answer_list)-1))\n",
    "                \n",
    "    if nld_l:\n",
    "        nld_l.sort(key=lambda x: x[0]) # nld 최솟값 정렬\n",
    "        if len(nld_l) == 1: # 하나만 뽑힘\n",
    "            return nld_l[0][1], nld_l[0][2], nld_l[0][3]\n",
    "        \n",
    "        elif nld_l[0][0] == nld_l[1][0]: # 여러개 뽑힌 것들 중에 동일한 NLD 존재\n",
    "            # 핵심 단어와의 유클리디안 거리를 통해 동일한 정답 중에서 최적을 선택\n",
    "            question_points = find_points(questions, words_list, boxes, ngrams=3)\n",
    "            \n",
    "            if not question_points:\n",
    "                return nld_l[0][1], nld_l[0][2], nld_l[0][3]\n",
    "          \n",
    "            candidates = []\n",
    "            for q in nld_l:\n",
    "                if q[0] == nld_l[0][0]:\n",
    "                    euc_dist = calculate_euclidean_mean(question_points, boxes[q[2]])\n",
    "                    heappush(candidates, [euc_dist, q[1], q[2], q[3]])\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            return candidates[0][1], candidates[0][2], candidates[0][3]\n",
    "        else: # 여러개 뽑힌 것들 중에 첫번째가 가장 적합함\n",
    "            return nld_l[0][1], nld_l[0][2], nld_l[0][3]\n",
    "    else:\n",
    "        return None, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class DocVQADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,split):\n",
    "        datasets = load_dataset(\"Trailblazer-Yoo/boostcamp-docvqa\")\n",
    "        if split=='train':\n",
    "          self.dataset = datasets['train']\n",
    "        else:\n",
    "          self.dataset = datasets['val']\n",
    "\n",
    "        try:\n",
    "          model_checkpoint = \"microsoft/layoutlmv2-large-uncased\"\n",
    "          self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "        except:\n",
    "          model_checkpoint = \"microsoft/layoutlmv2-large-uncased\"\n",
    "          self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "    def encode_dataset(self,example, max_length=512):\n",
    "          # take a batch \n",
    "          questions = example['question']\n",
    "          words = [w for w in example['words']] #handles numpy and list\n",
    "          boxes = example['boxes']\n",
    "\n",
    "          # encode it\n",
    "          encoding = self.tokenizer([questions], [words], [boxes], max_length=max_length, padding=\"max_length\", truncation=True,return_tensors=\"pt\")\n",
    "          batch_index=0\n",
    "          input_ids = encoding.input_ids[batch_index].tolist()\n",
    "\n",
    "          # next, add start_positions and end_positions\n",
    "          start_positions = []\n",
    "          end_positions = []\n",
    "          answers = example['answers']\n",
    "          #print(\"Batch index:\", batch_index)\n",
    "          cls_index = input_ids.index(self.tokenizer.cls_token_id)\n",
    "          # try to find one of the answers in the context, return first match\n",
    "          for answer in answers:\n",
    "            # 바뀐 부분 ####################################################################################################################\n",
    "            answer_list = answer.split()\n",
    "            match, word_idx_start, word_idx_end = find_candidates(answer_list, words, questions, boxes)\n",
    "            #if match:\n",
    "            #  break\n",
    "            # EXPERIMENT (to account for when OCR context and answer don't perfectly match):\n",
    "            if not match and len(answer)>1:\n",
    "              for i in range(len(answer), 0, -1):\n",
    "                  answer_i_list = (answer[:i-1] + answer[i:]).split()\n",
    "                  match, word_idx_start, word_idx_end = find_candidates(answer_i_list, words, questions, boxes)\n",
    "                  if match:\n",
    "                    break\n",
    "            #바뀐 부분 ####################################################################################################################\n",
    "            # END OF EXPERIMENT \n",
    "            if match:\n",
    "              sequence_ids = encoding.sequence_ids(batch_index)\n",
    "              # Start token index of the current span in the text.\n",
    "              token_start_index = 0\n",
    "              while sequence_ids[token_start_index] != 1:\n",
    "                  token_start_index += 1\n",
    "\n",
    "              # End token index of the current span in the text.\n",
    "              token_end_index = len(input_ids) - 1\n",
    "              while sequence_ids[token_end_index] != 1:\n",
    "                  token_end_index -= 1\n",
    "              \n",
    "              word_ids = encoding.word_ids(batch_index)[token_start_index:token_end_index+1]\n",
    "\n",
    "              hit=False\n",
    "              for id in word_ids:\n",
    "                if id == word_idx_start:\n",
    "                  start_positions.append(token_start_index)\n",
    "                  hit=True\n",
    "                  break\n",
    "                else:\n",
    "                  token_start_index += 1\n",
    "\n",
    "              if not hit:\n",
    "                  continue\n",
    "        \n",
    "              hit=False\n",
    "              for id in word_ids[::-1]:\n",
    "                if id == word_idx_end:\n",
    "                  end_positions.append(token_end_index)\n",
    "                  hit=True\n",
    "                  break\n",
    "                else:\n",
    "                  token_end_index -= 1\n",
    "\n",
    "              if not hit:\n",
    "                  end_positions.append(token_end_index)\n",
    "              \n",
    "              #print(\"Verifying start position and end position:\")\n",
    "              #print(\"True answer:\", answer)\n",
    "              #start_position = start_positions[-1]\n",
    "              #end_position = end_positions[-1]\n",
    "              #reconstructed_answer = tokenizer.decode(encoding.input_ids[batch_index][start_position:end_position+1])\n",
    "              #print(\"Reconstructed answer:\", reconstructed_answer)\n",
    "              #print(\"-----------\")\n",
    "            \n",
    "            #else:\n",
    "              #print(\"Answer not found in context\")\n",
    "              #print(\"-----------\")\n",
    "              #start_positions.append(cls_index)\n",
    "              #end_positions.append(cls_index)\n",
    "\n",
    "          if len(start_positions)==0:\n",
    "              return None\n",
    "        \n",
    "          ans_i = random.randrange(len(start_positions))\n",
    "\n",
    "          encoding = {\n",
    "                  'input_ids': encoding['input_ids'],\n",
    "                  'attention_mask': encoding['attention_mask'],\n",
    "                  'token_type_ids': encoding['token_type_ids'],\n",
    "                  'bbox': encoding['bbox'],\n",
    "                  'answers' : answers\n",
    "                  }\n",
    "          ## 바뀐 부분 example['image'].copy() -> example['image'].copy()[0]\n",
    "          encoding['image'] = torch.LongTensor(example['image'].copy()[0])\n",
    "          encoding['start_position'] = torch.LongTensor([start_positions[ans_i]])\n",
    "          encoding['end_position'] = torch.LongTensor([end_positions[ans_i]])\n",
    "\n",
    "          return encoding\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "      data = self.dataset[index]\n",
    "      data = self.encode_dataset(data)\n",
    "\n",
    "      if data is None:\n",
    "                #return self.__getitem__((index+1)%len(self))\n",
    "        index = random.randrange(len(self))\n",
    "        return self.__getitem__(index)\n",
    "\n",
    "      return data\n",
    "\n",
    "def collate(data):\n",
    "    return {\n",
    "            'input_ids': torch.cat([d['input_ids'] for d in data],dim=0),\n",
    "            'attention_mask': torch.cat([d['attention_mask'] for d in data],dim=0),\n",
    "            'token_type_ids': torch.cat([d['token_type_ids'] for d in data],dim=0),\n",
    "            'bbox': torch.cat([d['bbox'] for d in data],dim=0),\n",
    "            'image': torch.stack([d['image'] for d in data],dim=0),\n",
    "            'start_positions': torch.cat([d['start_position'] for d in data],dim=0),\n",
    "            'end_positions': torch.cat([d['end_position'] for d in data],dim=0),\n",
    "            'answers': [d['answers'] for d in data],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DocVQADataset('train')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2,collate_fn=collate, shuffle=True)\n",
    "sample = next(iter(dataloader))\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "org_model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/layoutlmv2-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_result = org_model.layoutlmv2(input_ids = sample['input_ids'],\n",
    "                    attention_mask = sample['attention_mask'],\n",
    "                    token_type_ids = sample['token_type_ids'],\n",
    "                    bbox = sample['bbox'],\n",
    "                    image = sample['image']    \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_result['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import MBartConfig, MBartForCausalLM, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "from transformers.file_utils import ModelOutput\n",
    "\n",
    "class BARTDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Donut Decoder based on Multilingual BART\n",
    "    Set the initial weights and configuration with a pretrained multilingual BART model,\n",
    "    and modify the detailed configurations as a Donut decoder\n",
    "\n",
    "    Args:\n",
    "        decoder_layer:\n",
    "            Number of layers of BARTDecoder\n",
    "        max_position_embeddings:\n",
    "            The maximum sequence length to be trained\n",
    "        name_or_path:\n",
    "            Name of a pretrained model name either registered in huggingface.co. or saved in local,\n",
    "            otherwise, `hyunwoongko/asian-bart-ecjk` will be set (using `transformers`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, decoder_layer: int, max_position_embeddings: int, name_or_path: Union[str, bytes, os.PathLike] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.decoder_layer = decoder_layer\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "             \"microsoft/layoutlmv2-base-uncased\" if not name_or_path else name_or_path\n",
    "        )\n",
    "\n",
    "        self.model = MBartForCausalLM(\n",
    "            config=MBartConfig(\n",
    "                is_decoder=True,\n",
    "                is_encoder_decoder=False,\n",
    "                add_cross_attention=True,\n",
    "                decoder_layers=self.decoder_layer,\n",
    "                max_position_embeddings=self.max_position_embeddings,\n",
    "                vocab_size=len(self.tokenizer),\n",
    "                scale_embedding=True,\n",
    "                add_final_layer_norm=True,\n",
    "            )\n",
    "        )\n",
    "        self.model.forward = self.forward  #  to get cross attentions and utilize `generate` function\n",
    "\n",
    "        self.model.config.is_encoder_decoder = True  # to get cross-attention\n",
    "        self.add_special_tokens([\"<sep/>\"])  # <sep/> is used for representing a list in a JSON\n",
    "        self.model.model.decoder.embed_tokens.padding_idx = self.tokenizer.pad_token_id\n",
    "        self.model.prepare_inputs_for_generation = self.prepare_inputs_for_inference\n",
    "\n",
    "        # weight init with asian-bart\n",
    "        if not name_or_path:\n",
    "            bart_state_dict = MBartForCausalLM.from_pretrained(\"hyunwoongko/asian-bart-ecjk\").state_dict()\n",
    "            new_bart_state_dict = self.model.state_dict()\n",
    "            for x in new_bart_state_dict:\n",
    "                if x.endswith(\"embed_positions.weight\") and self.max_position_embeddings != 1024:\n",
    "                    new_bart_state_dict[x] = torch.nn.Parameter(\n",
    "                        self.resize_bart_abs_pos_emb(\n",
    "                            bart_state_dict[x],\n",
    "                            self.max_position_embeddings\n",
    "                            + 2,  # https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/models/mbart/modeling_mbart.py#L118-L119\n",
    "                        )\n",
    "                    )\n",
    "                elif x.endswith(\"embed_tokens.weight\") or x.endswith(\"lm_head.weight\"):\n",
    "                    new_bart_state_dict[x] = bart_state_dict[x][: len(self.tokenizer), :]\n",
    "                else:\n",
    "                    new_bart_state_dict[x] = bart_state_dict[x]\n",
    "            self.model.load_state_dict(new_bart_state_dict)\n",
    "\n",
    "    def add_special_tokens(self, list_of_tokens: List[str]):\n",
    "        \"\"\"\n",
    "        Add special tokens to tokenizer and resize the token embeddings\n",
    "        \"\"\"\n",
    "        newly_added_num = self.tokenizer.add_special_tokens({\"additional_special_tokens\": sorted(set(list_of_tokens))})\n",
    "        if newly_added_num > 0:\n",
    "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "    def prepare_inputs_for_inference(self, input_ids: torch.Tensor, encoder_outputs: torch.Tensor, past=None, use_cache: bool = None, attention_mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: (batch_size, sequence_lenth)\n",
    "        Returns:\n",
    "            input_ids: (batch_size, sequence_length)\n",
    "            attention_mask: (batch_size, sequence_length)\n",
    "            encoder_hidden_states: (batch_size, sequence_length, embedding_dim)\n",
    "        \"\"\"\n",
    "        attention_mask = input_ids.ne(self.tokenizer.pad_token_id).long()\n",
    "        if past is not None:\n",
    "            input_ids = input_ids[:, -1:]\n",
    "        output = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"past_key_values\": past,\n",
    "            \"use_cache\": use_cache,\n",
    "            \"encoder_hidden_states\": encoder_outputs.last_hidden_state,\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        use_cache: bool = None,\n",
    "        output_attentions: Optional[torch.Tensor] = None,\n",
    "        output_hidden_states: Optional[torch.Tensor] = None,\n",
    "        return_dict: bool = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A forward fucntion to get cross attentions and utilize `generate` function\n",
    "\n",
    "        Source:\n",
    "        https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/models/mbart/modeling_mbart.py#L1669-L1810\n",
    "\n",
    "        Args:\n",
    "            input_ids: (batch_size, sequence_length)\n",
    "            attention_mask: (batch_size, sequence_length)\n",
    "            encoder_hidden_states: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            loss: (1, )\n",
    "            logits: (batch_size, sequence_length, hidden_dim)\n",
    "            hidden_states: (batch_size, sequence_length, hidden_size)\n",
    "            decoder_attentions: (batch_size, num_heads, sequence_length, sequence_length)\n",
    "            cross_attentions: (batch_size, num_heads, sequence_length, sequence_length)\n",
    "        \"\"\"\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.model.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.model.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.model.config.use_return_dict\n",
    "        outputs = self.model.model.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        logits = self.model.lm_head(outputs[0])\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return (loss,) + output if loss is not None else output\n",
    "\n",
    "        return ModelOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            decoder_attentions=outputs.attentions,\n",
    "            cross_attentions=outputs.cross_attentions,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_bart_abs_pos_emb(weight: torch.Tensor, max_length: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Resize position embeddings\n",
    "        Truncate if sequence length of Bart backbone is greater than given max_length,\n",
    "        else interpolate to max_length\n",
    "        \"\"\"\n",
    "        if weight.shape[0] > max_length:\n",
    "            weight = weight[:max_length, ...]\n",
    "        else:\n",
    "            weight = (\n",
    "                F.interpolate(\n",
    "                    weight.permute(1, 0).unsqueeze(0),\n",
    "                    size=max_length,\n",
    "                    mode=\"linear\",\n",
    "                    align_corners=False,\n",
    "                )\n",
    "                .squeeze(0)\n",
    "                .permute(1, 0)\n",
    "            )\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config확인용 프린트 안해도 됨 / 확인하고 싶으면 찍어보셈\n",
    "# from transformers import VisionEncoderDecoderConfig\n",
    "\n",
    "# config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = BARTDecoder(decoder_layer = 4,\n",
    "                    max_position_embeddings = 1536\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_result = decoder(input_ids = sample['input_ids'], \n",
    "                    encoder_hidden_states = enc_result['last_hidden_state']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
